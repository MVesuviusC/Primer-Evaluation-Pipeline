---
title: "primerEvalPipeline"
author: "Matt Cannon"
output: knitrBootstrap::bootstrap_document
params:
  outDir: evalOut
  primerFile: infile.txt
  blastLoc: blastn
  blastDb: nt
  taxonomyDb: taxonomyDb
  threads: 1
---


Using parameters:
https://bookdown.org/yihui/rmarkdown/params-knit.html

# example command to run on hush
rmarkdown::render("primerEvalPipeline.Rmd", 
  output_dir = "evalOut/",
  params = list(
    primerFile = "examplePrimerInputFile.txt",
    blastLoc = "/usr/local/packages/ncbi-blast+-2.7.1/bin/blastn",
    blastDb = "/local/projects-t3/SerreDLab-3/databases/blast/nt",
    taxonomyDb = "/local/projects-t3/SerreDLab-3/cannonm3/eDNA/bsPrimerBlast/taxaDb/taxonomy.db",
    threads = 6
  )
)

rmarkdown::render("primerEvalPipeline.Rmd", 
  output_dir = "mam16SOut/",
  params = list(
    outDir = "mam16SOut",
    primerFile = "examplePrimerInputMammal16S.txt",
    blastLoc = "/usr/local/packages/ncbi-blast+-2.7.1/bin/blastn",
    blastDb = "/local/projects-t3/SerreDLab-3/databases/blast/nt",
    taxonomyDb = "/local/projects-t3/SerreDLab-3/cannonm3/eDNA/bsPrimerBlast/taxaDb/taxonomy.db",
    threads = 20
  )
)

rmarkdown::render("primerEvalPipeline.Rmd", 
  output_dir = "Phlebovirus1Out/",
  params = list(
    outDir = "Phlebovirus1Out",
    primerFile = "examplePrimerInputPhlebovirus1.txt",
    blastLoc = "/usr/local/packages/ncbi-blast+-2.7.1/bin/blastn",
    blastDb = "/local/projects-t3/SerreDLab-3/databases/blast/nt",
    taxonomyDb = "/local/projects-t3/SerreDLab-3/cannonm3/eDNA/bsPrimerBlast/taxaDb/taxonomy.db",
    threads = 35
  )
)



# Primer evaluation

Put in paragraph explaining goals and general approach here



Target taxa needs to be a species, genus, family, order, class, phylum or kingdom 
  (For now, I need to work on this. The issue is creating the database using makeTaxonomyDb.pl. This script 
  uses the rankedlineage.dmp file from the NCBI taxdump, which only includes these taxonomic levels. I need
  to use the other files to parse out all the taxonomic levels, but doing this is going to be
  a huge pain due to the format they're in.)


# To do

  * Need to deal with multiple taxids per blast hit..... separated by ";"
  * Allow taxonomic levels other than sgfocpk
  * Move taxaCloud
  * Make sure taxaTarget entry can handle lowercase
  * Implement checks that each step succeeded
  * Output a warning if the reblast step has too many reads (define too many)
  * Implement measurement of distance to most similar species for each species and make average
    * break down by average distance to nearest species, genus, family? 
  * Change bsPrimerTree primer mismatch output so I can capture only on-target hits
  * put amplicon length into summary table
  * Make script to split primer file into multiple, file named by primer inside
  * add " Vector " and " construct " to bannedwords?

### Libraries
```{r loadLibraries, cache = FALSE, eval = TRUE}
library(knitr)
library(rmarkdown)
library(knitrBootstrap)
library(gridExtra)
library(tidyverse)
library(ggwordcloud)
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
```

## Setup
```{r setup, cache = FALSE, include = FALSE}
opts_chunk$set(fig.height = 10, 
               fig.width = 20, 
               cache = TRUE, 
               cache.path = paste(params$outDir, "/cache/", sep = ""), 
               cache.extra = list(params$primerFile))
```

Parameters used for knitting
```{r printParams, cache = FALSE, eval = TRUE}
print(params)
```

### Check for requirements
Programs
  * blast
  * blastdbcmd
  * mafft
Write permissions
```{r checkReqs, cache = FALSE, eval = TRUE}
# use knit_exit()
```



### Export bash variables
```{r exportBashVariables, cache = FALSE, eval = TRUE}
Sys.setenv(outDir = params$outDir)
Sys.setenv(primerFile = params$primerFile)
Sys.setenv(blastLoc = params$blastLoc)
Sys.setenv(blastDb = params$blastDb)
Sys.setenv(taxonomyDb = params$taxonomyDb)
Sys.setenv(threads = params$threads)
```

### Create directories

   # need to check if directories exist
```{bash mkdirs, eval = TRUE}
mkdir $outDir
mkdir ${outDir}
mkdir ${outDir}/didHit
mkdir ${outDir}/reBlastOut
mkdir ${outDir}/couldHaveHit
mkdir ${outDir}/figures
```

### Read in the input file with primers
columns are:
primerNameF primerF primerNameR primerR targetTaxa

```{r getPrimers, cache = FALSE, eval = TRUE}
primerDf <- read.delim(params$primerFile, header = FALSE, sep = "\t")
colnames(primerDf) <- c("PrimerFName", "PrimerF", "PrimerRName", "PrimerR", "TargetTaxa", "TargetLevel")
primerDf
targetTaxa <- as.character(primerDf$TargetTaxa[1]) # first letter should be capitalized - put in check
targetLevel <- tolower(as.character(primerDf$TargetLevel[1])) # needs to be lowercase to match later

Sys.setenv(targetTaxa = targetTaxa)

# check if primer file is in the right format and if not knit_exit()
```


## Write out file containing "banned" words
These are words found in species names that indicate that the species named is uncertain

  * sp.
  * cf.
  * isolate
  * uncultured
  * symbiont
  * unidentified

```{r bannedWords, cache = FALSE, eval = TRUE}
bannedWords <- c("sp\\.", "cf\\.", "isolate", "uncultured", "symbiont", "unidentified")
write(bannedWords, file = paste(params$outDir, "/bannedWords.txt", sep = ""), sep = "\t")
```

## Find amplifiable species and document amplicon length and primer mismatches

### Run bsPrimerBlast and bsPrimerTree

Need to check how bsPrimerBlast is handling indels and sequence retrieval when there is an indel

This outputs:

* ampliconLengths.txt
* primerMismatches.txt
* taxaSummary.txt
* seqsWithTaxa.fasta -- This file has the portion of the sequence matching the primers removed
* seqsWithTaxaAligned.fasta -- This file has the portion of the sequence matching the primers removed
* If plots were produced: 
    + tree.nwk
    + dendroInstructionFile_*.txt
    + treePlot_*.svg 

 #################### Need to make bsPrimerTree output full taxonomy of all amplifiable taxa


################### figure out how/if to pull in these perl scripts since they won't be in the folder
#```{r, echo = F, cache = FALSE}
#read_chunk('bsPrimerBlast.pl', labels = 'bsPrimerBlastCode')
#```
#```{perl bsPrimerBlastCode, eval = FALSE, cache = FALSE}
#```
#```{r, echo = F, cache = FALSE}
#read_chunk('bsPrimerTree.pl', labels = 'bsPrimerTreeCode')
#```
#```{perl bsPrimerTreeCode, eval = FALSE, cache = FALSE}
#```

```{bash bsPrimerTree, eval = TRUE}
bsPrimerBlast.pl \
      --primerInput ${primerFile} \
      --blastDb ${blastDb} \
      --blastVer ${blastLoc} \
      --proc ${threads} \
      | \
    bsPrimerTree.pl \
      --inFile - \
      --blastDb ${blastDb} \
      --taxDb ${taxonomyDb} \
      --outDir ${outDir}/bsPrimerTreeOut \
      --threads ${threads} \
      --noPlots \
      --maxSeqsPerSpecies 3
```

### Plot amplicon length distribution 
This includes all hits from all species, so there may be inflation of certain values if one or more species has tons of hits.
```{r plotAmpLens, dependson = 'bsPrimerTree', eval = TRUE}
ampLenDf <- read.delim(paste(params$outDir, "/bsPrimerTreeOut/ampliconLengths.txt", sep = ""), header = FALSE)

png(paste(params$outDir, "/figures/ampliconLens.png", sep = ""), width = 1000, height = 1000, res = 300)
  ggplot(ampLenDf, aes(x = V2)) + 
    geom_histogram(binwidth = 1) +
    ggtitle("Amplicon Lengths") +
    xlab("Amplicon Length (bp)") + 
    ylab("Count")
dev.off()
```

### List on-target hits
```{r listOnTargetHits, dependson = 'bsPrimerTree', eval = TRUE}
bsPrimerTreeHits <- read.delim(paste(params$outDir, "/bsPrimerTreeOut/taxaSummary.txt", sep = ""))
# The taxa level should always be lowercase, but might be supplied uppercase

# Make sure the provided taxaLevel argument is valid
if(!targetLevel %in% colnames(bsPrimerTreeHits)) {
  warning("The target taxonomic level (\"targetLevel\") provided in input options is not one of: ", paste(colnames(potentialHits), collapse = ", "))
  warning("Please modify target taxa and retry!")
  knit_exit()
}
# Get only on target hits
bsPrimerTreeHits <- subset(bsPrimerTreeHits, get(targetLevel) == targetTaxa)

# Get rid of hits with "banned" words
bsPrimerTreeHits <- as.data.frame(bsPrimerTreeHits[grep(paste(bannedWords, collapse = "|"), bsPrimerTreeHits$species, perl = T, invert = T),])

write.table(bsPrimerTreeHits, file = paste(params$outDir, "/didHit/SpeciesOnTarget.txt", sep = ""), sep = "\t", quote = F, row.names = F)
```

### Plot primer mismatch counts
Would like to instead plot number of mismatches for sub-taxa to show how bias might manifest
```{r plotPrimerMismatch, dependson = 'bsPrimerTree', eval = TRUE}
primerMismatches <- read.delim(paste(params$outDir, "/bsPrimerTreeOut/primerMismatches.txt", sep = ""))

primerMismatches$direction <- gsub("for", "Forward", primerMismatches$direction)
primerMismatches$direction <- gsub("rev", "Reverse", primerMismatches$direction)

png(paste(params$outDir, "/figures/primerTotalMismatches.png", sep = ""), width = 3000, height = 5000, res = 300)
  primerMismatches %>% 
  select(., class, order, family, direction, mismatchTotal) %>%
  gather(., "Level", "Name", -direction, -mismatchTotal) %>%
  filter(., is.na(Name) == FALSE) %>%
  group_by(., direction, mismatchTotal, Level, Name) %>%
  summarize(., Count = length(mismatchTotal)) %>%
  ungroup(.) %>%
  mutate(., Level = factor(Level, levels = c(c("class", "order", "family")))) %>%
  ggplot(., aes(x = Name, y = mismatchTotal, fill = Count, label = Count)) + 
      geom_tile() + 
      facet_wrap(~ direction + Level, ncol = 1, scales = "free_x", strip.position = "left") + 
      geom_text() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
      theme(legend.position = "none") +
      ggtitle("Total number of primer mismatches\nNumber in each box is the number of hits with that many mismatches") +
      xlab("") + 
      ylab("")
dev.off()

png(paste(params$outDir, "/figures/primer5PrimeMismatches.png", sep = ""), width = 3000, height = 5000, res = 300)
  primerMismatches %>% 
  select(., class, order, family, direction, mismatch5Prime) %>%
  gather(., "Level", "Name", -direction, -mismatch5Prime) %>%
  filter(., is.na(Name) == FALSE) %>%
  group_by(., direction, mismatch5Prime, Level, Name) %>%
  summarize(., Count = length(mismatch5Prime)) %>%
  ungroup(.) %>%
  mutate(., Level = factor(Level, levels = c(c("class", "order", "family")))) %>%
  ggplot(., aes(x = Name, y = mismatch5Prime, fill = Count, label = Count)) + 
      geom_tile() + 
      facet_wrap(~ direction + Level, ncol = 1, scales = "free_x", strip.position = "left") + 
      geom_text() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
      theme(legend.position = "none") +
      ggtitle("Total number of mismatches in the 5' end\nNumber in each box is the number of hits with that many mismatches") +
      xlab("") + 
      ylab("")
dev.off()

```

### Filter unique seqs
Keep unique sequences per species and blast those, to reduce duplicate hits within a species prior to other analyses to avoid eg. human causing massive skew of the data. 

#### Select only the on-target sequences and get rid of sequences with "N"s

```{r, echo = F, cache = FALSE}
read_chunk('scripts/filterFastaNs.pl', labels = 'selectOnTargetHitsCode')
```
```{perl selectOnTargetHitsCode, eval = FALSE, cache = FALSE}
```
```{bash selectOnTargetHits, dependson = 'bsPrimerTree', eval = TRUE}
grep -A1 "\-${targetTaxa}:" ${outDir}/bsPrimerTreeOut/seqsWithTaxa.fasta | grep -v "^--" | perl scripts/filterFastaNs.pl --fasta - > ${outDir}/seqsWithTaxaOnTarget.fasta
```

#### Keep unique sequence/species combinations 
```{r, echo = F, cache = FALSE}
read_chunk('scripts/uniqueFastaBySpeciesSeq.pl', labels = 'uniqueSeqsCode')
```
```{perl uniqueSeqsCode, eval = FALSE, cache = FALSE}
```
```{bash uniqueSeqs, dependson = 'trimPrimerSeqs', eval = TRUE}
perl scripts/uniqueFastaBySpeciesSeq.pl \
    --fasta ${outDir}/seqsWithTaxaOnTarget.fasta \
      > ${outDir}/seqsWithTaxaOnTargetUnique.fasta
```


## Blast amplifiable sequences

This needs to output format 7 (which includes headers) to be compatable with downstream code
```{bash blast, dependson = 'uniqueSeqs', eval = TRUE}
# split the file up into 500 fasta entry files to save on RAM in blast step
split -dl 1000 ${outDir}/seqsWithTaxaOnTargetUnique.fasta ${outDir}/splitSeqs

for file in ${outDir}/splitSeqs*
do
  ${blastLoc} \
      -task blastn \
      -db ${blastDb} \
      -query ${file} \
      -num_threads ${threads} \
      -outfmt "7 qseqid staxid score length qstart qend qlen sstart send slen sacc" \
      -max_hsps 1 \
      -max_target_seqs 10000 \
        >> ${outDir}/reBlastOut/blastResults.txt
done

rm ${outDir}/splitSeqs*
gzip -f ${outDir}/reBlastOut/blastResults.txt

```

### Get taxonomy of blast hits

#### Pull hit GI number out of the BLAST results

############### Need to deal with multiple taxids per blast hit..... separated by ";"

```{bash getTaxids, dependson = 'blast', eval = TRUE}
zcat ${outDir}/reBlastOut/blastResults.txt.gz | grep -v "#" | cut -f 2,2 | perl -pe 's/gi.//' | perl -pe 's/\|.+//' | sort | uniq > ${outDir}/reBlastOut/taxids.txt 
```


#### Get taxonomy information from NCBI

local taxonomy database is created by makeTaxonomyDb.pl. This script and getTaxaLocal.pl are available at:
(https://github.com/MVesuviusC/getTaxa/)

```{bash getTaxonomy, dependson = 'getTaxids', eval = TRUE}
getTaxaLocal.pl --dbName ${taxonomyDb} --taxids ${outDir}/reBlastOut/taxids.txt > ${outDir}/reBlastOut/taxaRaw.txt 
```

### Use taxonomy and blast output to keep all equal top hits
output: 

This script kicks out any hit where species name contains "banned words":

  * sp.
  * cf.
  * isolate
  * uncultured
  * symbiont
  * unidentified

that indicate that the taxonomy is uncertain


```{r, echo = F, cache = FALSE}
read_chunk('scripts/findTopBlastHitsWithTaxa.pl', labels = 'parseTopBlastHitsCode')
```
```{perl parseTopBlastHitsCode, eval = FALSE, cache = FALSE}
```
```{bash parseTopBlastHits, dependson = 'getTaxonomy', eval = TRUE}
perl scripts/findTopBlastHitsWithTaxa.pl \
    --blastIn ${outDir}/reBlastOut/blastResults.txt.gz \
    --taxa ${outDir}/reBlastOut/taxaRaw.txt \
    > ${outDir}/couldHaveHit/blastParsed.txt
```

### Count hits per rank
Estimate of the taxonomic specificity of the data generated by the primers

This counts, for each query sequence blasted above, the number of taxonomic groups at four levels ( ) are
hit. Essentially, this tells you, if you were to generate real data, how many species/genera/families/orders 
would you expect to match each sequence. 

need to deal with "banned" words - should pull these into scripts from a file to make for easy updating

```{bash countNumInRank, dependson = 'parseTopBlastHits', eval = TRUE}
perl scripts/countNumInRank.pl --input ${outDir}/couldHaveHit/blastParsed.txt --outDir ${outDir}
```


## Find species with sequences in the nt database that could have been found by bsPrimerBlast
banned words: sp., uncultured, unidentified, cf., isolate, symbiont

###### Need to deal with the situation where "N"s in the sequence prevent finding the primer
```{bash parsePotentialHits, dependson = 'parseTopBlastHits', eval = TRUE}
perl scripts/getPotentialHits.pl \
    --alignVar 10 \
    --taxa ${outDir}/reBlastOut/taxaRaw.txt \
    --blast ${outDir}/reBlastOut/blastResults.txt.gz \
    --primerFile ${primerFile} \
      > ${outDir}/couldHaveHit/potentialHits.txt
```

### Generate list of on-target species with sequences in the nt database

```{r listHitSpecies, dependson = 'parsePotentialHits', eval = TRUE}
potentialHits <- read.delim(paste(params$outDir, "/couldHaveHit/potentialHits.txt", sep = ""))
# The taxa level should always be lowercase, but might be supplied uppercase

# Make sure the provided taxaLevel argument is valid
if(!targetLevel %in% colnames(potentialHits)) {
  warning("The target taxonomic level (\"targetLevel\") provided in input options is not one of: ", paste(colnames(potentialHits), collapse = ", "))
  warning("Please modify target taxa and retry!")
  knit_exit()
}
# Get only on target hits
potentialHits <- subset(potentialHits, get(targetLevel) == targetTaxa)

# Get rid of hits with "banned" words
potentialSpecies <- as.data.frame(potentialHits[grep(paste(bannedWords, collapse = "|"), potentialHits$species, perl = T, invert = T),])

write.table(potentialSpecies, file = paste(params$outDir, "/couldHaveHit/potentialSpeciesOnTarget.txt", sep = ""), sep = "\t", quote = F, row.names = F)
```




## Pull it all together to make summary table
use:
Percent of species on target
  evalOut/bsPrimerTreeOut/taxaSummary.txt
  #output/summaryTable/OnTargetSpeciesCount_SpeciesList.txt
  #output/summaryTable/OffTargetSpeciesCount_SpeciesList.txt


Number of species found and in NCBI
  /couldHaveHit/potentialSpeciesOnTarget.txt
  #output/summaryTable/hitsSpeciesCount_SpeciesList.txt
  #output/summaryTable/potentialHitsSpeciesCount_species_list.txt

Primer taxonomic specificity
  output/blast/topHitSummary/family/${base}Counts.txt
  output/blast/topHitSummary/genus/${base}Counts.txt
  output/blast/topHitSummary/species/${base}Counts.txt

```{r makingSummaryTable, eval = TRUE}
summaryTable <- primerDf

### Percent of on-target amplifiable hits
taxaSummary <- read.delim(paste(params$outDir, "/bsPrimerTreeOut/taxaSummary.txt", sep = ""))
taxaSummary <- taxaSummary[grep(paste(bannedWords, collapse = "|"), taxaSummary$species, invert = T),]

################################### should use outDir/didHit/SpeciesOnTarget.txt

taxaSummaryOnTarget <- subset(taxaSummary, get(targetLevel) == targetTaxa)

summaryTable$onTargetSpeciesAmplifiedCount <- sum(taxaSummary[[targetLevel]] == targetTaxa, na.rm = T)

summaryTable$allSpeciesAmplifiedCount <- nrow(taxaSummary)

summaryTable$percentAmplifiedOnTarget <- 100 * (summaryTable$onTargetSpeciesAmplifiedCount / summaryTable$allSpeciesAmplifiedCount)


######  Make word cloud plot of taxa
############ Should put this somewhere else
forCloud <- taxaSummary %>%
  mutate(., Count = 1) %>%
  select(., -species) %>% # this adds too many entries and they should all have Count = 1.... 
  gather(., "Level", "Taxa", -Count) %>% 
  group_by(., Taxa,Level) %>% 
  summarize(., Count = sum(Count), log10Count = log10(sum(Count))) %>%
  ungroup() %>%
  group_by(., Level) %>% 
  mutate(., Percent = 100 * round(Count / sum(Count), 4)) %>%
  ungroup() %>%
  filter(., Percent > 0.5) %>%
  mutate(., Level = factor(Level, levels = colnames(taxaSummary[1:8]))) %>%
  mutate(., Taxa = replace_na(Taxa, "ND"))

png(filename = paste(params$outDir, "/figures/TaxaCloud.png", sep = ""), width = 4000, height = 4000, res = 600)
ggplot(forCloud, aes(label = paste(Taxa, " (", Percent, "%)", sep = ""), size = log10Count)) +
  geom_text_wordcloud_area(shape = "square") +
  scale_size_area(max_size = 3) +
  facet_wrap(~ Level, scales = "free") +
  ggtitle("Taxa greater than 0.5%")
dev.off()


#### Species that could have been amplified
potentialHits <- read.delim(file = paste(params$outDir, "/couldHaveHit/potentialSpeciesOnTarget.txt", sep = ""), header = T)
potentialSpecies <- as.character(unique(potentialHits$species))
potentialHits$WasHit <- potentialHits$species %in% potentialSpecies[potentialSpecies %in% taxaSummaryOnTarget$species]


missedSpecies <- potentialHits[potentialHits$species %in% potentialSpecies[!potentialSpecies %in% taxaSummaryOnTarget$species],]
                        
write.table(missedSpecies, file = paste(params$outDir, "/couldHaveHit/missedTaxa.txt", sep = ""), quote = F, sep = "\t", row.names = F)

PercentFound <- (length(potentialSpecies) - length(missedSpecies)) / length(potentialSpecies)

missedSummary <- potentialHits %>% 
  select(., -species) %>% 
  gather(., key = "Level", value = "Taxa", -WasHit) %>% 
  group_by(., Level, Taxa) %>% 
  summarize(., PercentHit = sum(WasHit) / length(WasHit), NumHit = sum(WasHit), NumMissed = length(WasHit) - sum(WasHit)) %>% 
  ungroup()

missedSummary$Level <- factor(missedSummary$Level, levels = c("species", "genus", "family", "order", "class", "phylum", "kingdom"))

png(filename = paste(params$outDir, "/figures/TaxaPercentAmplifiableByTaxa.png", sep = ""), width = 8000, height = 6000, res = 300)
ggplot(missedSummary, aes(x = reorder(Taxa, -PercentHit), y = PercentHit * 100)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~ Level, scales = "free_x", ncol = 1) +
  xlab("") + 
  ylab("Percent amplifiable") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
dev.off()

### Taxonomic specificity
topHitMeans <- read.delim(file = paste(params$outDir, "/topHitMeans.txt", sep = ""), header = T)
topHitMeans$TaxaLevel <- paste(topHitMeans$TaxaLevel, "- Mean#Taxa/Hit")
rownames(topHitMeans) <- topHitMeans$TaxaLevel
topHitMeans <- as.data.frame(t(topHitMeans))
topHitMeans <- topHitMeans[-1,]
rownames(topHitMeans) <- 1

summaryTable <- cbind(summaryTable, topHitMeans)

topHitSummary <- read.delim(file = paste(params$outDir, "/topHitSummary.txt", sep = ""), header = T)
topHitSummary <- topHitSummary %>% 
  group_by(., TaxaLevel) %>% 
  summarise(., PercentSingleHit = (sum(UniqueTaxaHit == 1) / length(UniqueTaxaHit))) %>% 
  ungroup() %>% 
  spread(., TaxaLevel, PercentSingleHit)

colnames(topHitSummary) <- paste(colnames(topHitSummary), "- Percent Single Hit")

summaryTable <- cbind(summaryTable, topHitSummary)

### primer mismatches


write.table(summaryTable, file = paste(params$outDir, "/OverallSummary.txt", sep = ""), quote = F, sep = "\t", row.names = F)

```


