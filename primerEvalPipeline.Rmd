---
title: "primerEvalPipeline"
author: "Matt Cannon"
output: knitrBootstrap::bootstrap_document
params:
  outDir: evalOut
  primerFile: infile.txt
  blastLoc: blastn
  blastDb: nt
  taxonomyDb: taxonomyDb
  threads: 1
---


Using parameters:
https://bookdown.org/yihui/rmarkdown/params-knit.html

# example command to run on hush
rmarkdown::render("primerEvalPipeline.Rmd", params = list(
  primerFile = "examplePrimerInputFile.txt",
  blastLoc = "/usr/local/packages/ncbi-blast+-2.7.1/bin/blastn",
  blastDb = "/local/projects-t3/SerreDLab-3/databases/blast/nt",
  taxonomyDb = "/local/projects-t3/SerreDLab-3/cannonm3/eDNA/bsPrimerBlast/taxaDb/taxonomy.db",
  threads = 6
))

# Primer evaluation

Put in paragraph explaining goals and general approach here



Target taxa needs to be a genus, family, order, class, phylum or kingdom (for now, I need to work on this)

### Libraries
```{r loadLibraries, cache = FALSE, eval = TRUE}
library(knitr)
library(rmarkdown)
library(knitrBootstrap)
library(gridExtra)
library(tidyverse)
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
```

## Setup
```{r setup, cache = FALSE, include = FALSE}
opts_chunk$set(fig.height = 10, fig.width = 20, cache = TRUE)
```

Parameters used for knitting
```{r printParams, cache = FALSE, eval = TRUE}
print(params)
```

### Check for requirements
Programs
Write permissions
```{r checkReqs, cache = FALSE, eval = TRUE}
# use knit_exit()
```



### Export bash variables
```{r exportBashVariables, cache = FALSE, eval = TRUE}
Sys.setenv(outDir = params$outDir)
Sys.setenv(primerFile = params$primerFile)
Sys.setenv(blastLoc = params$blastLoc)
Sys.setenv(blastDb = params$blastDb)
Sys.setenv(taxonomyDb = params$taxonomyDb)
Sys.setenv(threads = params$threads)
```

### Create directories
```{bash mkdirs, eval = FALSE}
mkdir $outDir
mkdir ${outDir}
mkdir ${outDir}/figures
mkdir ${outDir}/topHitSummary
#mkdir ${outDir}/sequences/trimmed
#mkdir ${outDir}/blast
#mkdir ${outDir}/blast/topParsed
#mkdir ${outDir}/blast/potentialHits
#mkdir misc
#mkdir ${outDir}/unrestrictedPrimerTree/
#mkdir ${outDir}/unrestrictedPrimerTree/primerTreeObj
#mkdir ${outDir}/unrestrictedPrimerTree/figures
#mkdir ${outDir}/unrestrictedPrimerTree/taxonomy
#mkdir ${outDir}/unrestrictedPrimerTree/sequences
#mkdir ${outDir}/primerDiffs
```

### Read in the input file with primers
columns are:
primerNameF primerF primerNameR primerR targetTaxa

```{r getPrimers, eval = TRUE}
primerDf <- read.delim(params$primerFile, header = FALSE, sep = "\t")
primerDf
# check if primers are in the right format and if not knit_exit()
```


## Find amplifiable species and document amplicon length and primer mismatches

### Run bsPrimerBlast and bsPrimerTree

Need to check how bsPrimerBlast is handling indels and sequence retrieval when there is an indel

This outputs:

* ampliconLengths.txt
* primerMismatches.txt
* taxaSummary.txt
* seqsWithTaxa.fasta -- This file has the portion of the sequence matching the primers removed
* seqsWithTaxaAligned.fasta -- This file has the portion of the sequence matching the primers removed
* If plots were produced: 
    + tree.nwk
    + dendroInstructionFile_*.txt
    + treePlot_*.svg 

################### figure out how/if to pull in these perl scripts since they won't be in the folder
#```{r, echo = F, cache = FALSE}
#read_chunk('bsPrimerBlast.pl', labels = 'bsPrimerBlastCode')
#```
#```{perl bsPrimerBlastCode, eval = FALSE, cache = FALSE}
#```
#```{r, echo = F, cache = FALSE}
#read_chunk('bsPrimerTree.pl', labels = 'bsPrimerTreeCode')
#```
#```{perl bsPrimerTreeCode, eval = FALSE, cache = FALSE}
#```

```{bash bsPrimerTree, dependson = 'getPrimers', eval = TRUE}
bsPrimerBlast.pl \
      --primerInput ${primerFile} \
      --blastDb ${blastDb} \
      --blastVer ${blastLoc} \
      --proc ${threads} \
      | \
    bsPrimerTree.pl \
      --inFile - \
      --blastDb ${blastDb} \
      --taxDb ${taxonomyDb} \
      --outDir ${outDir} \
      --threads ${threads} \
      --noPlots \
      --maxSeqsPerSpecies 3
```

### Plot amplicon length distribution 
This includes all hits from all species, so there may be inflation of certain values if one or more species has tons of hits.
```{r plotAmpLens, dependson = 'bsPrimerTree', eval = TRUE}
ampLenDf <- read.delim(paste(params$outDir, "/ampliconLengths.txt", sep = ""), header = FALSE)

png(paste(params$outDir, "/figures/ampliconLens.png", sep = ""), width = 1000, height = 1000, res = 300)
  ggplot(ampLenDf, aes(x = V2)) + 
    geom_histogram(binwidth = 1) +
    ggtitle("Amplicon Lengths") +
    xlab("Amplicon Length (bp)") + 
    ylab("Count")
dev.off()
```

### Plot primer mismatch counts
Would like to instead plot number of mismatches for sub-taxa to show how bias might manifest
```{r plotPrimerMismatch, dependson = 'bsPrimerTree', eval = TRUE}
primerMismatches <- read.delim(paste(params$outDir, "/primerMismatches.txt", sep = ""))

primerMismatches$Primer <- gsub(":.+", "", primerMismatches$TotalMismatches)
primerMismatches$Primer <- gsub("for", "Forward", primerMismatches$Primer)
primerMismatches$Primer <- gsub("rev", "Reverse", primerMismatches$Primer)
primerMismatches$TotalMismatches <- gsub(".+:", "", primerMismatches$TotalMismatches)

P1 <- ggplot(primerMismatches, aes(x = TotalMismatches, y = Count)) + 
          geom_bar(stat = "identity") + 
          facet_wrap(~ Primer) +
          ggtitle("Total number of mismatches in primer") +
          xlab("") +
          ylab("Number of sequences")

P2 <- ggplot(primerMismatches, aes(x = TipMismatches, y = Count)) + 
          geom_bar(stat = "identity") + 
          facet_wrap(~ Primer) +
          ggtitle("Mismatches in 3' end of primer") +
          xlab("") +
          ylab("Number of sequences")

png(paste(params$outDir, "/figures/primerMismatches.png", sep = ""), width = 2000, height = 2000, res = 300)
  grid.arrange(P1, P2, ncol = 1)
dev.off()
```

### Filter unique seqs
Keep unique sequences per species and blast those, to reduce duplicate hits within a species prior to other analyses to avoid eg. human causing massive skew of the data. 

```{r, echo = F, cache = FALSE}
read_chunk('scripts/uniqueFastaBySpeciesSeq.pl', labels = 'uniqueSeqsCode')
```
```{perl uniqueSeqsCode, eval = FALSE, cache = FALSE}
```
```{bash uniqueSeqs, dependson = 'trimPrimerSeqs', eval = TRUE}
perl scripts/uniqueFastaBySpeciesSeq.pl \
    --fasta ${outDir}/seqsWithTaxa.fasta \
      > ${outDir}/seqsWithTaxaUnique.fasta
```


## Blast amplifiable sequences
```{bash blast, dependson = 'uniqueSeqs', eval = TRUE}
${blastLoc} \
    -task blastn \
    -db ${blastDb} \
    -query ${outDir}/seqsWithTaxaUnique.fasta \
    -num_threads ${threads} \
    -outfmt "7 qseqid staxid score length qlen sstart send slen sacc" \
    -max_hsps 1 \
    -max_target_seqs 10000 \
    | gzip \
      > ${outDir}/blastResults.txt.gz
```

### Get taxonomy of blast hits

#### Pull hit GI number out of the BLAST results

############### Need to deal with multiple taxids per blast hit..... separated by ";"

```{bash getTaxids, dependson = 'blast', eval = TRUE}
zcat ${outDir}/blastResults.txt.gz | grep -v "#" | cut -f 2,2 | perl -pe 's/gi.//' | perl -pe 's/\|.+//' | sort | uniq > ${outDir}/taxids.txt 
```


#### Get taxonomy information from NCBI

local taxonomy database is created by makeTaxonomyDb.pl. This script and getTaxaLocal.pl are available at:
(https://github.com/MVesuviusC/getTaxa/)

```{bash getTaxonomy, dependson = 'getGi', eval = TRUE}
getTaxaLocal.pl --dbName ${taxonomyDb} --taxids ${outDir}/taxids.txt > ${outDir}/taxaRaw.txt 
```

### Use taxonomy and blast output to keep all equal top hits
output: 

```{r, echo = F, cache = FALSE}
read_chunk('scripts/findTopBlastHitsWithTaxa.pl', labels = 'parseTopBlastHitsCode')
```
```{perl parseTopBlastHitsCode, eval = FALSE, cache = FALSE}
```
```{bash parseTopBlastHits, dependson = 'getTaxonomy', eval = TRUE}
perl scripts/findTopBlastHitsWithTaxa.pl \
    --blastIn ${outDir}/blastResults.txt.gz \
    --taxa ${outDir}/taxaRaw.txt \
    > ${outDir}/blastParsed.txt 
```

### Count hits per rank
--> Need to check if the hits have taxonomy at this rank
need to kick out any hit where species contains "banned words" (sp., cf., isolate, uncultured......)

put in perlUnique.pl

maybe put this all into a perl script.... 

```{bash countNumInRank, dependson = 'parseTopBlastHits', eval = FALSE}
# family
  grep -v "query" ${outDir}/blastParsed.txt \
  | cut -f 1,9 | \
  awk -F "\t" '$2 != "NA" {print $_}' | sort | uniq | cut -f 1,1 | sort | uniq -c | perl -pe 's/^ +//' > ${outDir}/topHitSummary/familyCounts.txt

# genus
  grep -v "query" ${outDir}/blastParsed.txt | cut -f 1,10 | awk -F "\t" '$2 != "NA" {print $_}' | sort | uniq | cut -f 1,1 | sort | uniq -c | perl -pe 's/^ +//' > output/blast/topHitSummary/genus/${base}Counts.txt

# species
  grep -v "query" ${outDir}/blastParsed.txt | cut -f 1,11 | awk -F "\t" '$2 != "NA" {print $_}' | sort | uniq | cut -f 1,1 | sort | uniq -c | perl -pe 's/^ +//' > output/blast/topHitSummary/species/${base}Counts.txt
```




```{bash listHitSpecies, dependson = 'getTaxonomy', eval = FALSE}

################
######### Double check field cuts
################

#banned words: sp., uncultured, unidentified, cf., isolate, symbiont

grep Apicomplexa output/taxonomy/Apicomplexa18S_365_F_Apicomplexa18S_613_R_taxonomyFixed.txt | cut -f 3,3 | grep -v "sp\." | grep -v "unidentified" | grep -v "cf\." | grep -v "isolate" | grep -v "symbiont" | grep -v "^NA$" | sort | uniq > output/taxonomy/Apicomplexa18S_365_F_Apicomplexa18S_613_R_SpeciesList.txt
 
## parabasalia is distinct due to taxonomy
########################### check
grep -f parabasaliaGenera.txt output/taxonomy/Parabasalia18S_288_F_Parabasalia18S_654_R_taxonomyFixed.txt | cut -f 3,3 | grep -v "sp\." | grep -v "cf\." | grep -v "isolate" | grep -v "unidentified" | grep -v "symbiont" |  grep -v "^NA$" | sort | uniq > output/taxonomy/Parabasalia18S_288_F_Parabasalia18S_654_R_SpeciesList.txt

wc -l output/taxonomy/*SpeciesList.txt | perl -pe 's/^\s+//' > output/summaryTable/hitsSpeciesCount_SpeciesList.txt

```


## Find missed hits
banned words: sp., uncultured, unidentified, cf., isolate, symbiont
```{bash parsePotentialHits, dependson = 'parseTopBlastHits', eval = FALSE}
# Apicomplexa
perl scripts/getPotentialHits.pl \
    --alignVar 10 \
    --taxa output/blast/blastTaxa.txt \
    --blast output/blast/Apicomplexa18S_365_F_Apicomplexa18S_613_R_blastResults.txt \
    
    # change this to input primerFile
    --primerF GACCTATCAGCTTTCGACGG \
    --primerR CCCTCCAATTGWTACTCTGGR \
      > output/blast/potentialHits/Apicomplexa18S_365_F_Apicomplexa18S_613_R_potential_hits.txt

# Parabasalia
perl misc/getPotentialHits.pl --alignVar 10 --taxa output/blast/blastTaxa.txt --blast output/blast/Parabasalia18S_288_F_Parabasalia18S_654_R_blastResults.txt --primerF TAGGCTATCACGGGTAACGG --primerR GCGTCCTGATTTGTTCACAG > output/blast/potentialHits/Parabasalia18S_288_F_Parabasalia18S_654_R_potential_hits.txt
```

### 

```{r countUniqueSpecies, engine = 'bash', eval = FALSE}
grep Apicomplexa output/blast/potentialHits/Apicomplexa18S_365_F_Apicomplexa18S_613_R_potential_hits.txt | cut -f 8,8 | grep -v species | sort | uniq | grep -v "^NA$" | perl -pe 's/_/ /' > output/blast/potentialHits/Apicomplexa18S_365_F_Apicomplexa18S_613_R_species_list.txt

wc -l output/blast/potentialHits/*_species_list.txt | perl -pe 's/^\s+//' > output/summaryTable/potentialHitsSpeciesCount_species_list.txt
```





## Make up summary table
use:
Percent of species on target
  output/summaryTable/OnTargetSpeciesCount_SpeciesList.txt
  output/summaryTable/OffTargetSpeciesCount_SpeciesList.txt

Number of species found and in NCBI
  output/summaryTable/hitsSpeciesCount_SpeciesList.txt
  output/summaryTable/potentialHitsSpeciesCount_species_list.txt

Primer taxonomic specificity
  output/blast/topHitSummary/family/${base}Counts.txt
  output/blast/topHitSummary/genus/${base}Counts.txt
  output/blast/topHitSummary/species/${base}Counts.txt

```{r makingSummaryTable, eval = FALSE}
#############################################
### Number of species found and in NCBI total
foundCounts <- read.delim("output/summaryTable/hitsSpeciesCount_SpeciesList.txt", header = F, sep = " ")
colnames(foundCounts) <- c("Species found", "Primer")
foundCounts <- subset(foundCounts, Primer != "total")
foundCounts$Primer <- gsub(".+/", "", foundCounts$Primer)
foundCounts$Primer <- gsub("_SpeciesList.txt", "", foundCounts$Primer)

potentialCounts <- read.delim("output/summaryTable/potentialHitsSpeciesCount_species_list.txt", header = F, sep = " ")
colnames(potentialCounts) <- c("Species In NCBI", "Primer")
potentialCounts <- subset(potentialCounts, Primer != "total")
potentialCounts$Primer <- gsub(".+/", "", potentialCounts$Primer)
potentialCounts$Primer <- gsub("_species_list.txt", "", potentialCounts$Primer)

summaryTable <- merge(foundCounts, potentialCounts, all = T)

summaryTable$`Species In NCBI` <- paste(
  prettyNum(summaryTable$`Species In NCBI`, big.mark = ","), 
  " (", 
  round(100 * (summaryTable$`Species found` / summaryTable$`Species In NCBI`), digits = 1), 
  "%)", 
  sep = "")

summaryTable$`Species found` <- prettyNum(summaryTable$`Species found`, big.mark = ",")

rownames(summaryTable) <- summaryTable$Primer

##############################################
### Mean number of species matching each blast query and % single match
for(tLevel in c("family", "genus", "species")) {
  specificityFiles <- list.files(paste("output/blast/topHitSummary/", tLevel, "/", sep = ""), pattern = "Counts.txt", full.names = T)
  for(inFile in specificityFiles) {
    Primer <- gsub(".+/", "", inFile)
    Primer <- gsub("Counts.txt", "", Primer)
    
    dataDf <- read.delim(inFile, header = F, sep = " ")
    
    summaryTable[Primer, paste(tLevel, " mean", sep = "")] <- round(mean(dataDf$V1), digits = 1)
    
    summaryTable[Primer, paste(tLevel, " % single", sep = "")] <- paste(round(100 * (sum(dataDf$V1 == 1) / length(dataDf$V1)), digits = 1), "%", sep = "")
  }
}

###############################################
### % species on target
onTargetCounts <- read.delim("output/summaryTable/OnTargetSpeciesCount_SpeciesList.txt", header = F, sep = " ")
colnames(onTargetCounts) <- c("On target", "Primer")
onTargetCounts <- subset(onTargetCounts, Primer != "total")
onTargetCounts$Primer <- gsub(".+/", "", onTargetCounts$Primer)
onTargetCounts$Primer <- gsub("_SpeciesList.txt", "", onTargetCounts$Primer)
onTargetCounts$Primer <- gsub("On_", "", onTargetCounts$Primer)

summaryTable <- merge(summaryTable, onTargetCounts, all = T)

offTargetCounts <- read.delim("output/summaryTable/OffTargetSpeciesCount_SpeciesList.txt", header = F, sep = " ")
colnames(offTargetCounts) <- c("Off target", "Primer")
offTargetCounts <- subset(offTargetCounts, Primer != "total")
offTargetCounts$Primer <- gsub(".+/", "", offTargetCounts$Primer)
offTargetCounts$Primer <- gsub("_SpeciesList.txt", "", offTargetCounts$Primer)
offTargetCounts$Primer <- gsub("Off_", "", offTargetCounts$Primer)

summaryTable <- merge(summaryTable, offTargetCounts, all = T)

summaryTable$`% Species on-target` <- paste(round(100 * (summaryTable$`On target` / (summaryTable$`On target` + summaryTable$`Off target`)), digits = 1), "%", sep = "")

rownames(summaryTable) <- summaryTable$Primer

##############################################
### reorder rows
properOrder <- c("Amoebozoa_18S_2_rev", "Apicomplexa", "Apicomplexa18S_365_F_Apicomplexa18S_613_R", "Eimeriorina18S_302_F_Eimeriorina18S_730_R", "Plasmodium18S_883_F_Plasmodium18S_1126_R", "Blastocystis18S_F_Blastocystis18S_R", "Diplomonadida_768_F_Diplomonadida_1059_R", "Kinetoplastida_18S_4_Kinetoplastida_18S_4", "Microsporidia_18S_F_Microsporidia_18S_R", "Nematoda", "Spirurida18S_1435_F_Spirurida18S_1858_R", "Spirurida18S_F2_Spirurida18S_R2", "Trichocephalida18S2_F_Trichocephalida18S2_R", "Parabasalia18S_288_F_Parabasalia18S_654_R", "Platyhelminthes_18S3_F_Platyhelminthes_18S3_R")

summaryTable <- summaryTable[properOrder,]

colnames(summaryTable) <- gsub("family", "Family", colnames(summaryTable))
colnames(summaryTable) <- gsub("genus", "Genus", colnames(summaryTable))
colnames(summaryTable) <- gsub("species", "Species", colnames(summaryTable))

write.table(summaryTable, file = 'output/summaryTable/finalTable.txt', quote = F, sep = "\t", row.names = F, col.names = T, na = "")

```


